# фиксируем seed для воспроизводимости результатов 
set.seed(10)

# подключаем необходимые библиотеки
library(tidyverse)
library(rio)
library(lmtest)
library(psych)
library(car)
library(mctest)
library(sandwich)

# устанавливаем рабочую директорию
# setwd("~/Documents/Studies/Econometrics/HW/A")

# загружаем данные
data = import('forestfires.csv')

### задание 1

# фильтруем нулевые значения целевой переменной
data = filter(data, data$area != 0)

# необходимость лог-трансформации целевой переменной?
hist(data$area, xlab = 'Значение переменной area', ylab = 'Частота появления',
     main = 'Распределение переменной area')
data = mutate(data, log_area = log(data$area + 1))
hist(data$log_area, xlab = 'Значение log(area + 1)', ylab = 'Частота появления',
     main = 'Распределение log(area + 1)')

# переменная month: бинаризуем на два полугодия, чтобы не включать 11 разных дамми-переменных
data$winter_season = as.numeric(data$month == 'sep' | data$month == 'oct' | 
                                  data$month == 'nov' | data$month == 'dec' | 
                                  data$month == 'jan' | data$month == 'feb')

# переменная day: бинаризуем на weekday и weekend, которые выявляют эффект дня недели 
data$weekend = as.numeric(data$day == 'sat' | data$day == 'sun')

# факторизуем географические координаты, которые задаются в формате от 1 до 9
data$X = factor(data$X)
data$Y = factor(data$Y)

# логарифмируем влажность и добавляем квадрат скорости ветра (см. обоснование в задании 2)
data = mutate(data, log_RH = log(data$RH), wind2 = data$wind * data$wind)

### задание 2 

model = lm(data = data, log_area ~ DMC + DC + log_RH + wind + wind2 + 
             winter_season + weekend + X + Y)

# в нашу модель входят следующие признаки:

  # DMC (Duff Moisture Code) и DC (Drought Code) из канадской системы Fire Weather Index:

      # эти признаки влияют на fire intensity [Cortez and Morais, 2007], а значит, 
      # и на площадь сгоревшей территории; знак определить в данном случае сложно,
      # поскольку непонятна направленность показателей, но, вероятнее всего,
      # знаки у них будут противоположные (moisture vs drought)

  # log_RH, wind и wind2 из признаков погодных условий:

      # temp и rain уже учитываются в DMC и DC [Cortez and Morais, 2007]

      # RH учитывается в DMC, но не учитывается в DC, и мы берем лог-трансформированный признак,
      # потому что эмпирически так оказалось лучше (с точки зрения значимости коэффициента),
      # знак должен получиться отрицательным, ибо влажность препятствует пожару

      # wind не учитывается в тех индексах, поэтому мы включаем эту переменную и ее квадрат,
      # зависимость может быть квадратической, поскольку сперва скорость ветра способствует пожару,
      # однако слишком сильный ветер может способствовать затуханию бедствия,
      # ожидаем положительный коэффициент при wind и отрицательный при wind2 
      # (парабола ветвями вниз с вершиной на положительном луче оси абсцисс)

  # winter_season и weekend из времени возникновения пожара:

      # winter_season, который разделяет зимне-осенние и летне-весенние месяцы, но довольно трудно 
      # предугадать знак, потому что есть много различных погодных и человеческих факторов

      # weekend показывает, является ли день пожара выходным днем, 
      # ожидается положительный коэффициент, который учитывает человеческий фактор:
      # люди приходят на природу в выходные и могут спровоцировать пожар 

  # географические факторные координаты X и Y (некоторые дамми-переменные для них оказались значимы):

      # здесь предсказать знак, конечно же, невозможно 

# в целом из признаков взаимодействия можно было бы включить, например, взаимодействие между rain
# и weekend, если бы у rain было больше ненулевых значений (они почти все ноль в данном датасете),
# и тогда человеческий фактор выходных учитывался бы ввиду дождя (в дождливую погоду вряд ли кто-то
# пойдет на природу жечь костры или выкидывать мусор), но, к сожалению, это взаимодействие 
# невозможно включить в регрессию, а другие не имеют смысла либо оказываются незначимыми 

# описательные статистики:
X = select(data, log_area, DMC, DC, log_RH, wind, winter_season, weekend, X, Y)
d = select(describe(X), n, mean, median, sd, min, max)
d # здесь вместо дисперсии -- стандартное отклонение

# гистограммы:
hist(data$log_area, xlab = 'Значение log(area + 1)', ylab = 'Частота появления',
     main = 'Распределение log(area + 1)')
hist(data$DMC, xlab = 'Значение переменной DMC', ylab = 'Частота появления',
     main = 'Распределение переменной DMC')
hist(data$DC, xlab = 'Значение переменной DC', ylab = 'Частота появления',
     main = 'Распределение переменной DC')
hist(data$log_RH, xlab = 'Значение log(RH)', ylab = 'Частота появления',
     main = 'Распределение log(RH)')
hist(data$wind, xlab = 'Значение переменной wind', ylab = 'Частота появления',
     main = 'Распределение переменной wind')
# все гистограммы выглядят адекватно и даже немного похожи на нормальное распределение 

# ящики с усами:

boxplot(data$log_area, horizontal = T, xlab = 'Значение log(area + 1)', ylab = 'Размах',
        main = 'Диграмма размаха log(area + 1)')
# некоторое количество выбросов справа и есть определенная несимметричность, 
# но мы и так уже лог-трансформировали переменную area

boxplot(data$DMC, horizontal = T, xlab = 'Значение переменной DMC', ylab = 'Размах',
        main = 'Диграмма размаха переменной DMC')
# много выбросов справа, но это свидетельствует об экстремальных значениях temp/rain/RH,
# однако это специфика данной переменной и мы оставим все как есть

boxplot(data$DC, horizontal = T, xlab = 'Значение переменной DC', ylab = 'Размах',
        main = 'Диграмма размаха переменной DC')
# много выбросов слева, но это свидетельствует об экстремальных значениях temp/rain,
# однако это специфика данной переменной и мы оставим все как есть

boxplot(data$log_RH, horizontal = T, xlab = 'Значение log(RH)', ylab = 'Размах',
        main = 'Диграмма размаха log(RH)')
# выбросов почти нет, данные симметричны, обработка не требуется

boxplot(data$wind, horizontal = T, xlab = 'Значение переменной wind', ylab = 'Размах',
        main = 'Диграмма размаха переменной wind')
# выбросов почти нет, данные симметричны, обработка не требуется 

### задание 3

# VIF:

vif(model) # мультиколлинеарность не выявлена, поскольку все коэффициенты вздутия дисперсии < 10

# CN:

# убираем факторные переменные X и Y, с которыми не работает данный тест,
# и wind2, поскольку эта переменная коррелирует с переменной wind:
model0 = lm(data = data, log_area ~ DMC + DC + log_RH + wind + winter_season + weekend) 
model1 = lm(data = data, log_area ~ DMC + DC + log_RH + wind + wind2 + winter_season + weekend) 

omcdiag(model0) # CN = 12.8449 < 30 => мультиколлинеарность не выявлена
omcdiag(model1) # CN = 29.1506 из-за квадрата wind2, но все равно меньше 30 :) 

### задание 4

summary(model)

# интерпретация:

# коэффициент при DMC = 0.0050263 (значим на уровне 0.01)
    # с ростом DMC на 1 площадь сгораемой территории растет на 0.50%
    # сложно для интерпретации, поскольку показатель считается комплексно на основе погодных данных
    # но хорошо для прогнозирования 

# коэффициент при DC = -0.0015061 (значим на уровне 0.01)
    # с ростом DC на 1 площадь сгораемой территории падает на 0.15%
    # сложно для интерпретации, поскольку показатель считается комплексно на основе погодных данных
    # но хорошо для прогнозирования 

# коэффициент при log(RH) = -0.4730464 (значим на уровне 0.05)
    # с ростом относительной влажности на 1% площадь сгораемой территории падает на 0.47%
    # в целом ожидаемый знак взаимосвязи, поскольку влажность действительно препятствует огню 

# коэффициент при wind = 0.3434589 (значим на уровне 0.05)
# коэффициент при wind2 = -0.0318494 (значим на уровне 0.05)
    # wind(вершина) = -0.3434589 / (2 * -0.0318494) = 5.391921
    # если wind < 5.391921, то увеличение скорости ветра могло бы потенциально увеличить area 
    # если wind > 5.391921, то увеличение скорости ветра могло бы потенциально снизить area
    # ожидаемые результаты по знакам, см. ранее
    # предельные эффекты при таком характере зависимости необходимо считать отдельно

# коэффициент при winter_season = 0.7309616 (значим на уровне 0.001)
    # факт возникновения пожара зимой/осенью увеличивает площадь сгораемой территории на 73% (шок!)
    # это очень необычный результат, поскольку летом обычно ожидается больше сильных пожаров 
    # однако из-за того, что летом эта вероятность выше, возможно, пожарные менее готовы к тушению
    # поэтому площадь сгораемой территории выше (психологический фактор?)
    # кроме того, зимой/осенью, может быть, просто сложнее тушить (погодные условия?)
    # или же данная территория более популярна у посетителей в зимне-осенний период (как у weekend)

# коэффициент при weekend = 0.3607199 (значим на уровне 0.01)
    # факт возникновения пожара на выходных увеличивает площадь сгораемой территории на 36% 
    # в выходные больше вероятность возникновения пожаров из-за человеческого фактора
    # к тому же из-за большого наплыва их тогда сложнее тушить (нужно эвакуировать и т.д.)

# отдельные коэффициенты при дамми-переменных, связанных с координатами X и Y, получились значимы
    # это X9, Y5, Y8, Y9... можно было бы еще здесь включить переменные взаимодействия
    # но тогда модель получилась бы слишком сложной 

# значимость: 

    # все рассмотренные коэффициенты получились значимы хотя бы на уровне 5% (не считая факторных)

    # все переменные в целом также значимы, F-тест: p-value = 0.0001698 => 
    # есть основания отвергнуть гипотезу H0 о незначимости регрессии в целом 

# Multiple R-squared = 0.1841
# Adjusted R-squared = 0.1151 
# в общем и целом сойдет 

# нормальность остатков:
res = model$residuals
shapiro.test(res) 
# p-value = 7.674e-06 => гипотеза H0 о нормальности распределения остатков отвергается
# на любом разумном уровне значимости => попробуем процедуру бутстрепа
# однако будем это делать для моделей без географических координат 

coef = c() # вектор для сохранения коэффициентов 
for (i in 1:10000)
{
  sample = sample(1:nrow(data), size = nrow(data), replace = T) # случайные индексы с повторами
  df = data[sample,] # применение индексов 
  m = lm(data = df, log_area ~ DMC + DC + log_RH + wind + wind2 + winter_season + weekend)
  coef = c(coef, unname(m$coefficients)) # добавляем полученные коэффициенты к вектору
}
coefm = matrix(coef, nrow = 10000, byrow = T, 
               dimnames = list(1:10000, names(model$coefficients)[1:8])) 
coefm = data.frame(coefm) 
coefd = describe(coefm)[,c('n', 'mean', 'se')] # se - стандартная ошибка среднего sd / sqrt(n)
coefd = mutate(coefd, left = coefd$mean - qt(0.975, df = coefd$n - 1) * coefd$se,
               right = coefd$mean + qt(0.975, df = coefd$n - 1) * coefd$se)
coefd = data.frame(coefd, coef = names(model$coefficients)[1:8])
coefd[c('coef', 'left', 'mean', 'right')]

### задание 5

newdata = data.frame(DMC = median(data$DMC), DC = median(data$DC), log_RH = median(data$log_RH),
                     wind = median(data$wind), wind2 = median(data$wind2), 
                     winter_season = median(data$winter_season), weekend = median(data$weekend),
                     X = d['X', 'median'], Y = d['Y', 'median'])
newdata$X = factor(newdata$X)
newdata$Y = factor(newdata$Y)

# точечный прогноз 
predict(model, newdata = newdata) # для логарифма сгоревшей площади
exp(predict(model, newdata = newdata)) # для сгоревшей площади

# индивидуальный прогноз 
predict(model, newdata = newdata, interval = 'prediction') # для логарифма сгоревшей площади
exp(predict(model, newdata = newdata, interval = 'prediction')) # для сгоревшей площади

# прогноз для среднего
predict(model, newdata = newdata, interval = 'confidence')  # для логарифма сгоревшей площади
exp(predict(model, newdata = newdata, interval = 'confidence'))  # для сгоревшей площади

### задание 6

# возможно, есть взаимосвязь между значениями DMC и/или DC (temp/rain) и дисперсией ошибок,
# поскольку чем более экстремальны значения этих переменных, тем, например, сильнее влияние
# случайных факторов, которые не могут быть учтены в регрессии, отчего увеличиваются остатки 

### задание 7

# графически:

res2 = res * res

plot(data$DMC, res2, xlab = 'Значение регрессора DMC', ylab = 'Остатки регрессии в квадрате',
     main = 'График квадратов остатков в зависимости от DMC')
# есть небольшое увеличение разброса с ростом значений регрессора

plot(data$DC, res2, xlab = 'Значение регрессора DC', ylab = 'Остатки регрессии в квадрате',
     main = 'График квадратов остатков в зависимости от DC')
# тоже небольшое увеличение разброса с ростом значений регрессора

# однако не факт, что это свидетельствует о гетероскедастичности по данным переменным
# поэтому проведем тест ГК и удостоверимся 

# тест Голдфельда-Квандта:

gqtest(model, order.by = ~ DMC, data = data, fraction = 0.2)
# p-value = 0.03756
# гипотеза H0 об условной гомоскедастичности отвергается на уровне значимости 5%
# проблема гетероскедастичности в целом вполне возможна для данной переменной

gqtest(model, order.by = ~ DC, data = data, fraction = 0.2)
# p-value = 0.2948 
# гипотеза H0 об условной гомоскедастичности не отвергается на любом разумном уровне значимости 
# проблема гетероскедастичности не имеет место для данной переменной 

### задание 8 

# источник реализации: https://rpubs.com/mpfoley73/500818 

# определяем веса для наблюдений:
weights = 1 / lm(abs(model$residuals) ~ model$fitted.values)$fitted.values^2

# реализуем ВМНК:
model_WLS = lm(data = data, weights = weights, 
            log_area ~ DMC + DC + log_RH + wind + wind2 + winter_season + weekend + X + Y)

# сравниваем МНК и ВМНК:
summary(model)
summary(model_WLS)
# коэффициенты уменьшились по модулю, стандартные ошибки снизились;
# в плане значимости некоторые коэффициенты стали менее значимы (p-value выше: DMC, DC, log(RH), 
# winter_season, weekend), а некоторые -- более значимы (p-value ниже: wind, wind2);
# из более-менее четырех значимых дамми-переменных при X и Y осталась значимой только одна (Y == 9)

### задание 9 

HC0 = vcovHC(model, type = 'HC0') # робастная оценка ковариационной матрицы в форме Уайта HC0
# идея в том, чтобы использовать квадраты остатков из обычной МНК-регрессии;
# диагональная матрица с этими квадратами подставляется в формулу для ковариационной матрицы;
# стандартные ошибки в данном случае будут определяться, как обычно, квадратными корнями
# диагональных элементов получившейся ковариационной матрицы 

HC3 = vcovHC(model1, type = 'HC3') # робастная оценка ковариационной матрицы в форме Уайта HC3
# современная форма HC3 не оценивается при использовании факторных переменных X и Y (поэтому model1),
# но и в целом, как оказалось, данные переменные оказались не столь ценными в нашей модели 

# используем HC0:
coeftest(model)
coeftest(model, vcov. = HC0)
# стандартные ошибки действительно изменились, однако не так сильно, чтобы принципиально изменить 
# значимость коэффициентов в нашей модели (все звездочки остались как есть);
# единственное -- дамми-переменные по X и Y: при робастных ошибках выросла значимость Y8 и Y9

# используем HC3:
coeftest(model1)
coeftest(model1, vcov. = HC3)
# стандартные ошибки действительно изменились, однако не так сильно, чтобы принципиально изменить 
# значимость коэффициентов в нашей модели (все звездочки остались как есть)

### задание 10 

# метод главных компонент с предварительной стандартизацией переменных:
X0 = select(data, DMC, DC, log_RH, wind, winter_season, weekend) # без целевой и факторных 
pca = prcomp(X0, scale = T)

# выборочная дисперсия каждой компоненты:
summary(pca) # две первые компоненты объясняют суммарно 50.70% выборочной дисперсии

# извлекаем две первые главные компоненты:
pca1 = pca$x[,1]
pca2 = pca$x[,2]

# однако они довольно плохо коррелируют с log(area):
cor(data$log_area, pca1)
cor(data$log_area, pca2)

# строим линейную регрессию на две первые главные компоненты:
model_PCA = lm(data$log_area ~ pca1 + pca2)
summary(model1)
summary(model_PCA)
# к сожалению, объясняющая способность модели с PCA лишь снизилась (с R-sq = 0.09187 до 0.0007282) 
# главные компоненты оказались незначимыми переменными в модели, поэтому данный способ не работает 
# и к тому же регрессия в целом незначима (p-value = 0.9073 для F-теста)

### веселая задачка на десятку 

# обойдемся без факторных географических переменных, т.е. нужно будет сравнивать с model1

# источник реализации: https://www.ime.unicamp.br/~cnaber/optim_1.pdf

# выписываем ML-функцию в предпосылке о нормальности распределения остатков:
ml = function(theta, y, X) # theta -- вектор, содержащий оценки коэффициентов и sigma2
{
  n = nrow(X) # количество наблюдений
  k = ncol(X) + 1 # количество коэффициентов (пересечение + для всех признаков)
  beta = theta[2:k] # вектор признаков
  sigma2 = theta[k + 1]
  e = y - theta[1] - X %*% beta # остатки
  logl = -0.5 * n * log(2 * pi) - 0.5 * n * log(sigma2) - ((t(e) %*% e) / (2 * sigma2))
  return(-logl)
}

# максимизируем ML-функцию:
start = c(rnorm(ncol(X) + 1), 1) # вектор стартовых значений
y = data$log_area
X = data.matrix(select(data, DMC, DC, log_RH, wind, wind2, winter_season, weekend))
mle = optim(start, ml, method = 'BFGS', y = y, X = X) # оптимизатор

summary(model1)$coefficients[,1] # вспоминаем оценки OLS
mle$par # оценки ML с помощью встроенных методов оптимизации
# они совпадают с довольно высокой степенью точности 
